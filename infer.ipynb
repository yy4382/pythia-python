{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/torch-base/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-410m\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.bos_token = tokenizer.eos_token\n",
    "print(tokenizer.eos_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
    "### Instruction: Write a Python program to quick sort a list.\n",
    "### Input: [1,2,2,3,4,5]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"save/trl-sft/complete/1\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-410m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(inputs, max_new_tokens=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/torch-base/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "config = PeftConfig.from_pretrained(\"save/lora/incomplete/2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, \"save/lora/incomplete/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
      "### Instruction: Write a Python program to quick sort a list.\n",
      "### Input: [1,2,2,3,4,5]\n",
      "### Output: [1,2,3,4,5]\n",
      "Here is a Python program that quick sort a list of integers:\n",
      "\n",
      "```python\n",
      "def quick_sort(lst):\n",
      "    if len(lst) <= 1:\n",
      "        return lst\n",
      "    else:\n",
      "        mid = len(lst) // 2\n",
      "        left_half = lst[:mid]\n",
      "        right_half = lst[mid:]\n",
      "        return quick_sort(left_half) + quick_sort(right_half)\n",
      "\n",
      "# Test the program\n",
      "lst = [1,2,2,3,4,5]\n",
      "print(quick_sort(lst))\n",
      "```\n",
      "\n",
      "Output:\n",
      "```\n",
      "[1, 2, 3, 4, 5]\n",
      "```\n",
      "\n",
      "In this program, the `quick_sort` function takes a list as input and returns the sorted list. The `if` statement checks if the length of the list is less than or equal to 1. If so, it returns the list as it is already sorted. Otherwise, it creates a new list and recursively calls the `quick_sort` function with the left and right halves of the list. The `if` statement checks if the length of the left half is greater than the length of the right half. If so, it returns the left half as it is already sorted. Otherwise, it creates a new list and recursively calls the `quick\n"
     ]
    }
   ],
   "source": [
    "outputLang = tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
    "print(outputLang[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
